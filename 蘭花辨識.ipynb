{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vMwOMngA6JqX","outputId":"1687b48c-e4b1-4d7b-ec53-5eb2419799f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","#/content/drive/My Drive/Colab Notebooks/medical image/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sqmlJWSU4PH8","outputId":"6fc5d4dc-ab36-4719-c9cc-126b47bc703b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Mar 13 13:04:31 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J2JrUYAquQLe"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"Pf61VGa45bbz"},"source":["#Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"djEjYlZc41Y0"},"outputs":[],"source":["from torch.utils.data import Dataset\n","from pathlib import Path\n","from PIL import Image\n","import os\n","\n","\n","class IMAGE_Dataset(Dataset):\n","    def __init__(self, root_dir, label_root,transform=None):\n","        self.root_dir = Path(root_dir)\n","        self.label_root = Path(label_root)\n","        self.image = []\n","        self.label = []\n","        self.transform = transform\n","        #print(self.root_dir.name)\n","        \n","        flower_path = os.listdir(root_dir)\n","        with open(label_root, newline='') as csvfile:\n","            rows = csv.DictReader(csvfile)\n","            for row in rows:\n","              for i ,image in enumerate(flower_path):\n","                self.image.append(image)\n","                if image == row[\"filename\"]:\n","                  self.label.append(int(row[\"category\"]))\n","        print(self.image)\n","        print(self.label)\n","    def __len__(self):\n","        return len(self.image)\n","\n","    def __getitem__(self, index):\n","        image = Image.open(self.image[index])\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, self.label[index]\n"]},{"cell_type":"markdown","metadata":{"id":"MXHKRDZ85nEq"},"source":["#VGG16"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JHvPtux75taR"},"outputs":[],"source":["import torch.nn as nn\n","import math\n","\n","X = 256\n","\n","class VGG16(nn.Module):\n","    def __init__(self, num_classes=1000):\n","        super(VGG16, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            \n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","        self.classifier = nn.Sequential(\n","            # input shape: (batch_size, 3, 224, 224) and\n","            # downsampled by a factor of 2^5 = 32 (5 times maxpooling)\n","            # So features' shape is (batch_size, 7, 7, 512)\n","            nn.Linear(in_features=7 * 7 * 512, out_features=X),\n","            nn.ReLU(),\n","            nn.Dropout(),\n","            nn.Linear(in_features=X, out_features=X),\n","            nn.ReLU(),\n","            nn.Dropout(),\n","            nn.Linear(in_features=X, out_features=num_classes)\n","        )\n","\n","        # initialize parameters\n","        for module in self.modules():\n","            if isinstance(module, nn.Conv2d):\n","                n = module.kernel_size[0] * module.kernel_size[1] * module.out_channels\n","                module.weight.data.normal_(0, math.sqrt(2. / n))\n","                module.bias.data.zero_()\n","            elif isinstance(module, nn.Linear):\n","                module.weight.data.normal_(0, 0.01)\n","                module.bias.data.zero_()\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        # flatten\n","        x = x.view(x.size(0), -1)\n","        x = self.classifier(x)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9yqMCF7ft5is"},"outputs":[],"source":["class Block(nn.Module):\n","  def __init__(self,in_channels,out_channels,stride=1):\n","    super(Block,self).__init__()\n","    self.plain=nn.Sequential(\n","        nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU(),\n","        nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(out_channels)\n","    )\n","    #判斷strides是否等於1，輸出入channel是否相等，否就做downsample使用1x1convolution(stride=2=>3x3=>1x1)\n","    if stride!=1 or in_channels!=out_channels: \n","      self.shortcut=nn.Sequential(\n","          nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n","          nn.BatchNorm2d(out_channels)\n","      )\n","    self.short_cut=(stride!=1) or (in_channels!=out_channels)\n","  def forward(self,inputs):\n","    x=self.plain(inputs)\n","    if not self.short_cut:\n","      shortcut=inputs\n","    else:\n","      shortcut=self.shortcut(inputs)\n","    # print(x.shape)\n","    # print(shortcut.shape)\n","    return x+shortcut\n","\n","class ResNet(nn.Module):\n","  def __init__(self):\n","    super(ResNet, self).__init__()\n","    self.model=nn.Sequential(\n","        Block(3,64),\n","        Block(64,64),\n","        Block(64,256,2),\n","\n","        Block(256,128),\n","        Block(128,128),\n","        Block(128,512,2),\n","\n","        Block(512,256),\n","        Block(256,256),\n","        Block(256,1024,2),\n","\n","        Block(1024,512),\n","        Block(512,512),\n","        Block(512,2048,2),\n","\n","        nn.AdaptiveAvgPool2d((1,1)),\n","        nn.Flatten(),\n","        nn.Linear(2048,2048),\n","        nn.ReLU(),\n","        nn.Dropout(0.2),\n","        nn.Linear(2048,2048),\n","        nn.ReLU(),\n","        nn.Dropout(0.2),\n","        nn.Linear(2048, 2)\n","    )\n","  def forward(self,inputs):\n","    # x=self.block1(inputs)\n","    y=self.model(inputs)\n","    return y"]},{"cell_type":"markdown","metadata":{"id":"Zok09BP65uou"},"source":["#Train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"kEbNduk_50Fr","outputId":"ce4bdeca-005f-4101-b243-b1911d49a3f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1/30 --- < Starting Time : Sun Mar 13 15:33:38 2022 >\n","------------------------------------------------------------\n","Training loss: 1.3414\taccuracy: 0.6439\n","\n","Accuracy of   cnv :   6.6667 %\n","Accuracy of   pcv :  72.0000 %\n","\n","Accuracy on the ALL test images: 39.3333 %\n","Epoch: 2/30 --- < Starting Time : Sun Mar 13 15:34:17 2022 >\n","------------------------------------------------------------\n","Training loss: 0.5310\taccuracy: 0.7446\n","\n","Accuracy of   cnv :  13.3333 %\n","Accuracy of   pcv :  70.0000 %\n","\n","Accuracy on the ALL test images: 41.6667 %\n","Epoch: 3/30 --- < Starting Time : Sun Mar 13 15:34:55 2022 >\n","------------------------------------------------------------\n","Training loss: 0.4296\taccuracy: 0.8094\n","\n","Accuracy of   cnv :  39.3333 %\n","Accuracy of   pcv :  45.3333 %\n","\n","Accuracy on the ALL test images: 42.3333 %\n","Epoch: 4/30 --- < Starting Time : Sun Mar 13 15:35:33 2022 >\n","------------------------------------------------------------\n","Training loss: 0.3212\taccuracy: 0.8633\n","\n","Accuracy of   cnv :  11.3333 %\n","Accuracy of   pcv :  67.3333 %\n","\n","Accuracy on the ALL test images: 39.3333 %\n","Epoch: 5/30 --- < Starting Time : Sun Mar 13 15:36:13 2022 >\n","------------------------------------------------------------\n","Training loss: 0.3267\taccuracy: 0.8705\n","\n","Accuracy of   cnv :  10.0000 %\n","Accuracy of   pcv :  65.3333 %\n","\n","Accuracy on the ALL test images: 37.6667 %\n","Epoch: 6/30 --- < Starting Time : Sun Mar 13 15:36:52 2022 >\n","------------------------------------------------------------\n","Training loss: 0.2312\taccuracy: 0.9110\n","\n","Accuracy of   cnv :  31.3333 %\n","Accuracy of   pcv :  40.0000 %\n","\n","Accuracy on the ALL test images: 35.6667 %\n","Epoch: 7/30 --- < Starting Time : Sun Mar 13 15:37:30 2022 >\n","------------------------------------------------------------\n","Training loss: 0.1084\taccuracy: 0.9658\n","\n","Accuracy of   cnv :  29.3333 %\n","Accuracy of   pcv :  32.6667 %\n","\n","Accuracy on the ALL test images: 31.0000 %\n","Epoch: 8/30 --- < Starting Time : Sun Mar 13 15:38:09 2022 >\n","------------------------------------------------------------\n","Training loss: 0.0858\taccuracy: 0.9739\n","\n","Accuracy of   cnv :  30.0000 %\n","Accuracy of   pcv :  28.6667 %\n","\n","Accuracy on the ALL test images: 29.3333 %\n","Epoch: 9/30 --- < Starting Time : Sun Mar 13 15:38:47 2022 >\n","------------------------------------------------------------\n","Training loss: 0.0556\taccuracy: 0.9775\n","\n","Accuracy of   cnv :  25.3333 %\n","Accuracy of   pcv :  29.3333 %\n","\n","Accuracy on the ALL test images: 27.3333 %\n","Epoch: 10/30 --- < Starting Time : Sun Mar 13 15:39:26 2022 >\n","-------------------------------------------------------------\n","Training loss: 0.0396\taccuracy: 0.9892\n","\n","Accuracy of   cnv :  20.6667 %\n","Accuracy of   pcv :  31.3333 %\n","\n","Accuracy on the ALL test images: 26.0000 %\n","Epoch: 11/30 --- < Starting Time : Sun Mar 13 15:40:04 2022 >\n","-------------------------------------------------------------\n","Training loss: 0.0318\taccuracy: 0.9901\n","\n","Accuracy of   cnv :  26.6667 %\n","Accuracy of   pcv :  26.0000 %\n","\n","Accuracy on the ALL test images: 26.3333 %\n","Epoch: 12/30 --- < Starting Time : Sun Mar 13 15:40:43 2022 >\n","-------------------------------------------------------------\n","Training loss: 0.0335\taccuracy: 0.9910\n","\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-4905dd9ed617>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-30-4905dd9ed617>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_data_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCUDA_DEVICES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCUDA_DEVICES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-82588b89ac45>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    899\u001b[0m         \"\"\"\n\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exclusive_fp\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_exclusive_fp_after_loading\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import torch\n","import torch.nn as nn\n","# from Model_VGG16 import VGG16\n","# from dataset import IMAGE_Dataset\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","from pathlib import Path\n","import copy\n","import time\n","import os\n","import torchvision.models as models\n","##REPRODUCIBILITY\n","torch.manual_seed(0)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","#args = parse_args()\n","#CUDA_DEVICES = args.cuda_devices\n","#DATASET_ROOT = args.path\n","CUDA_DEVICES = 0\n","DATASET_ROOT = '/content/drive/My Drive/flower/train/'\n","DATASET_valROOT = '/content/drive/My Drive/flower/val/'\n","PATH_TO_WEIGHTS = '/content/model-0.80-best_train_acc.pth' # Your model name\n","\n","# Initial learning rate\n","init_lr = 0.01\n","\n","# Save model every 5 epochs\n","checkpoint_interval = 5\n","\n","# Setting learning rate operation\n","def adjust_lr(optimizer, epoch):\n","    \n","    # 1/10 learning rate every 5 epochs\n","    lr = init_lr * (0.1 ** (epoch // 5))\n","    \n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","\n","def train():\n","    data_transform = transforms.Compose([\n","        transforms.Resize((480,480)),\n","        # transforms.RandomCrop(224, pad_if_needed=True),\n","        # transforms.RandomRotation(2.8),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","        ])\n","    #print(DATASET_ROOT)\n","    train_set = IMAGE_Dataset(Path(DATASET_ROOT), data_transform)\n","    \n","    # If out of memory , adjusting the batch size smaller\n","    data_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True, num_workers=0)#16改128\n","\n","    val_set = IMAGE_Dataset(Path(DATASET_valROOT), data_transform)\n","    val_data_loader = DataLoader(dataset=val_set, batch_size=64, shuffle=True, num_workers=0)\n","    classes = [classname for _dir in range(0,219)]\n","    classes.sort()\n","    classes.sort(key = len)\n","    #print(train_set.num_classes)\n","    # model = VGG16(num_classes=train_set.num_classes)\n","    # model = ResNet()\n","    model=models.shufflenet_v2_x1_0(pretrained=True)\n","    model = model.cuda(CUDA_DEVICES)\n","\n","    model.train()\n","\n","    best_model_params = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","    \n","    # Training epochs\n","    num_epochs = 30 #20改3\n","    criterion = nn.CrossEntropyLoss()\n","    \n","    # Optimizer setting\n","    # optimizer = torch.optim.SGD(params=model.parameters(), lr=init_lr, momentum=0.9)\n","    optimizer = torch.optim.Adam(params=model.parameters(), lr=init_lr)\n","\n","    # Log \n","    with open('TrainingAccuracy.txt','w') as fAcc:\n","        print('Accuracy\\n', file = fAcc)\n","    with open('TrainingLoss.txt','w') as fLoss:\n","        print('Loss\\n', file = fLoss)\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        localtime = time.asctime( time.localtime(time.time()) )\n","        print('Epoch: {}/{} --- < Starting Time : {} >'.format(epoch + 1,num_epochs,localtime))\n","        print('-' * len('Epoch: {}/{} --- < Starting Time : {} >'.format(epoch + 1,num_epochs,localtime)))\n","\n","        training_loss = 0.0\n","        training_corrects = 0\n","        adjust_lr(optimizer, epoch)\n","\n","        for i, (inputs, labels) in enumerate(data_loader):\n","            inputs = Variable(inputs.cuda(CUDA_DEVICES))\n","            labels = Variable(labels.cuda(CUDA_DEVICES))\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs.data, 1)\n","            loss = criterion(outputs, labels)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            training_loss += float(loss.item() * inputs.size(0))\n","            training_corrects += torch.sum(preds == labels.data)\n","        training_loss = training_loss / len(train_set)\n","        training_acc = training_corrects.double() /len(train_set)\n","        print('Training loss: {:.4f}\\taccuracy: {:.4f}\\n'.format(training_loss,training_acc))\n","        \n","\n","        # Check best accuracy model ( but not the best on test )\n","        if training_acc > best_acc:\n","            best_acc = training_acc\n","            best_model_params = copy.deepcopy(model.state_dict())\n","\n","\n","        with open('TrainingAccuracy.txt','a') as fAcc:\n","            print('{:.4f} '.format(training_acc), file = fAcc)\n","        with open('TrainingLoss.txt','a') as fLoss:\n","            print('{:.4f} '.format(training_loss), file = fLoss)\n","\n","        # Checkpoint\n","        if (epoch + 1) % checkpoint_interval == 0:\n","            torch.save(model, '/content/drive/My Drive/Colab Notebooks/medical image/model-epoch-{:d}-train.pth'.format(epoch + 1))\n","        # DATASET_valROOT = '/content/drive/My Drive/Colab Notebooks/medical image/test/'\n","    # PATH_TO_WEIGHTS = '/content/model-0.54-best_train_acc.pth' # Your model name\n","\n","    \n","\n","    # Load model\n","    # model = torch.load(PATH_TO_WEIGHTS)\n","    # model = model.cuda(CUDA_DEVICES)\n","        model.eval()\n","        total_correct = 0\n","        total = 0\n","        class_correct = list(0. for i in enumerate(classes))\n","        class_total = list(0. for i in enumerate(classes))\n","\n","        with torch.no_grad():\n","            for inputs, labels in val_data_loader:\n","                inputs = Variable(inputs.cuda(CUDA_DEVICES))\n","                labels = Variable(labels.cuda(CUDA_DEVICES))\n","                outputs = model(inputs)\n","                _, predicted = torch.max(outputs.data, 1)\n","                \n","                # totoal\n","                total += labels.size(0)\n","                total_correct += (predicted == labels).sum().item()\n","                c = (predicted == labels).squeeze()\n","                \n","                # batch size\n","                for i in range(labels.size(0)):\n","                    label = labels[i]\n","                    class_correct[label] += c[i].item()\n","                    class_total[label] += 1\n","\n","            for i, c in enumerate(classes):\n","                print('Accuracy of %5s : %8.4f %%' % (\n","                c, 100 * class_correct[i] / class_total[i]))\n","\n","            # Accuracy\n","            print('\\nAccuracy on the ALL test images: %.4f %%'\n","              % (100 * total_correct / total))\n","    # Save best training/valid accuracy model ( not the best on test )\n","    model.load_state_dict(best_model_params)\n","    best_model_name = '/content/drive/My Drive/Colab Notebooks/medical image/model-{:.2f}-best_train_acc.pth'.format(best_acc)\n","    torch.save(model, best_model_name)\n","    print(\"Best model name : \" + best_model_name)\n","\n","\n","if __name__ == '__main__':\n","    train()\n","    \n"]},{"cell_type":"markdown","metadata":{"id":"-qlrbY_tGFIh"},"source":["#val"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zzKJGmVuGCjn"},"outputs":[],"source":["import torch\n","# from utils import parse_args\n","from torch.autograd import Variable\n","from torchvision import transforms\n","from pathlib import Path\n","from PIL import Image\n","from torch.utils.data import DataLoader\n","# from dataset import IMAGE_Dataset\n","import numpy as np\n","\n","CUDA_DEVICES = 0\n","DATASET_valROOT = '/content/drive/My Drive/Colab Notebooks/medical image/val/'\n","PATH_TO_WEIGHTS = '/content/model-0.54-best_train_acc.pth' # Your model name\n","\n","\n","def val():\n","    CUDA_DEVICES = 0\n","    DATASET_valROOT = '/content/drive/My Drive/Colab Notebooks/medical image/test/'\n","    # PATH_TO_WEIGHTS = '/content/model-0.54-best_train_acc.pth' # Your model name\n","\n","    data_transform = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[\n","                             0.229, 0.224, 0.225])\n","    ])\n","    val_set = IMAGE_Dataset(Path(DATASET_valROOT), data_transform)\n","    val_data_loader = DataLoader(\n","        dataset=val_set, batch_size=32, shuffle=True, num_workers=0)\n","    classes = [_dir.name for _dir in Path(DATASET_valROOT).glob('*')]\n","    classes.sort()\n","    classes.sort(key = len)\n","\n","    # Load model\n","    # model = torch.load(PATH_TO_WEIGHTS)\n","    # model = model.cuda(CUDA_DEVICES)\n","    model.eval()\n","    total_correct = 0\n","    total = 0\n","    class_correct = list(0. for i in enumerate(classes))\n","    class_total = list(0. for i in enumerate(classes))\n","\n","    with torch.no_grad():\n","        for inputs, labels in val_data_loader:\n","            inputs = Variable(inputs.cuda(CUDA_DEVICES))\n","            labels = Variable(labels.cuda(CUDA_DEVICES))\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            \n","            # totoal\n","            total += labels.size(0)\n","            total_correct += (predicted == labels).sum().item()\n","            c = (predicted == labels).squeeze()\n","            \n","            # batch size\n","            for i in range(labels.size(0)):\n","                label = labels[i]\n","                class_correct[label] += c[i].item()\n","                class_total[label] += 1\n","\n","    for i, c in enumerate(classes):\n","        print('Accuracy of %5s : %8.4f %%' % (\n","        c, 100 * class_correct[i] / class_total[i]))\n","\n","    # Accuracy\n","    print('\\nAccuracy on the ALL test images: %.4f %%'\n","      % (100 * total_correct / total))\n","\n","\n","\n","# if __name__ == '__main__':\n","#     test()"]},{"cell_type":"markdown","metadata":{"id":"u8VWhXTn50sm"},"source":["#test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KhG0T3vu513D","outputId":"9b67b75f-803c-410d-8201-d0fc0d42a8ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of   cnv :  46.6258 %\n","Accuracy of   pcv :  79.0850 %\n","\n","Accuracy on the ALL test images: 62.3418 %\n"]}],"source":["import torch\n","# from utils import parse_args\n","from torch.autograd import Variable\n","from torchvision import transforms\n","from pathlib import Path\n","from PIL import Image\n","from torch.utils.data import DataLoader\n","# from dataset import IMAGE_Dataset\n","import numpy as np\n","\n","CUDA_DEVICES = 0\n","DATASET_ROOT = '/content/drive/My Drive/Colab Notebooks/medical image/test/'\n","PATH_TO_WEIGHTS = '/content/drive/My Drive/Colab Notebooks/medical image/model-epoch-10-train.pth' # Your model name\n","\n","\n","def test():\n","    data_transform = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[\n","                             0.229, 0.224, 0.225])\n","    ])\n","    test_set = IMAGE_Dataset(Path(DATASET_ROOT), data_transform)\n","    data_loader = DataLoader(\n","        dataset=test_set, batch_size=32, shuffle=True, num_workers=0)\n","    classes = [_dir.name for _dir in Path(DATASET_ROOT).glob('*')]\n","    classes.sort()\n","    classes.sort(key = len)\n","\n","    # Load model\n","    model = torch.load(PATH_TO_WEIGHTS)\n","    model = model.cuda(CUDA_DEVICES)\n","    model.eval()\n","    \n","\n","    total_correct = 0\n","    total = 0\n","    class_correct = list(0. for i in enumerate(classes))\n","    class_total = list(0. for i in enumerate(classes))\n","\n","    with torch.no_grad():\n","        for inputs, labels in data_loader:\n","            inputs = Variable(inputs.cuda(CUDA_DEVICES))\n","            labels = Variable(labels.cuda(CUDA_DEVICES))\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            \n","            # totoal\n","            total += labels.size(0)\n","            total_correct += (predicted == labels).sum().item()\n","            c = (predicted == labels).squeeze()\n","            \n","            # batch size\n","            for i in range(labels.size(0)):\n","                label = labels[i]\n","                class_correct[label] += c[i].item()\n","                class_total[label] += 1\n","\n","    for i, c in enumerate(classes):\n","        print('Accuracy of %5s : %8.4f %%' % (\n","        c, 100 * class_correct[i] / class_total[i]))\n","\n","    # Accuracy\n","    print('\\nAccuracy on the ALL test images: %.4f %%'\n","      % (100 * total_correct / total))\n","\n","\n","\n","if __name__ == '__main__':\n","    test()"]},{"cell_type":"markdown","metadata":{"id":"AVmbwbu-54oP"},"source":["#util(不用跑~)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ri6aqdqB56Yl"},"outputs":[],"source":["import argparse\n","\n","def parse_args():\n","    desc = 'PyTorch example code for Kaggle competition -- Plant Seedlings Classification.\\n' \\\n","           'See https://www.kaggle.com/c/plant-seedlings-classification'\n","    parser = argparse.ArgumentParser(description=desc)\n","    parser.add_argument('-p', '--path', help='path to dataset')\n","    parser.add_argument('-w', '--weight', help='path to model weights')\n","    parser.add_argument('-c', '--cuda_devices', type=int, help='path to model weights')\n","    return parser.parse_args()"]}],"metadata":{"accelerator":"GPU","colab":{"name":"蘭花辨識.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}