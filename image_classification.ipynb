{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15925,"status":"ok","timestamp":1647784585677,"user":{"displayName":"林楷軒","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02820282684866856866"},"user_tz":-480},"id":"vMwOMngA6JqX","outputId":"2757eb26-f154-4eea-ef8c-e74b11e70857"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","#/content/drive/My Drive/Colab Notebooks/medical image/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1647784585678,"user":{"displayName":"林楷軒","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02820282684866856866"},"user_tz":-480},"id":"sqmlJWSU4PH8","outputId":"68643ad9-5188-4f20-d24e-9e006a38032d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Mar 20 13:56:25 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   52C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J2JrUYAquQLe"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"Pf61VGa45bbz"},"source":["#Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"djEjYlZc41Y0"},"outputs":[],"source":["from torch.utils.data import Dataset\n","from pathlib import Path\n","from PIL import Image\n","\n","\n","class IMAGE_Dataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.root_dir = Path(root_dir)\n","        self.x = []\n","        self.y = []\n","        self.transform = transform\n","        self.num_classes = 0\n","        #print(self.root_dir.name)\n","        for i, _dir in enumerate(self.root_dir.glob('*')):\n","            for file in _dir.glob('*'):\n","                self.x.append(file)\n","                self.y.append(i)\n","\n","            self.num_classes += 1\n","            #print(self.num_classes)\n","        #print(self.num_classes)\n","    def __len__(self):\n","        return len(self.x)\n","\n","    def __getitem__(self, index):\n","        image = Image.open(self.x[index]).convert('RGB')\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, self.y[index]\n"]},{"cell_type":"markdown","metadata":{"id":"MXHKRDZ85nEq"},"source":["#VGG16"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JHvPtux75taR"},"outputs":[],"source":["import torch.nn as nn\n","import math\n","\n","X = 256\n","\n","class VGG16(nn.Module):\n","    def __init__(self, num_classes=1000):\n","        super(VGG16, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            \n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","\n","            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2)\n","        )\n","        self.classifier = nn.Sequential(\n","            # input shape: (batch_size, 3, 224, 224) and\n","            # downsampled by a factor of 2^5 = 32 (5 times maxpooling)\n","            # So features' shape is (batch_size, 7, 7, 512)\n","            nn.Linear(in_features=7 * 7 * 512, out_features=X),\n","            nn.ReLU(),\n","            nn.Dropout(),\n","            nn.Linear(in_features=X, out_features=X),\n","            nn.ReLU(),\n","            nn.Dropout(),\n","            nn.Linear(in_features=X, out_features=num_classes)\n","        )\n","\n","        # initialize parameters\n","        for module in self.modules():\n","            if isinstance(module, nn.Conv2d):\n","                n = module.kernel_size[0] * module.kernel_size[1] * module.out_channels\n","                module.weight.data.normal_(0, math.sqrt(2. / n))\n","                module.bias.data.zero_()\n","            elif isinstance(module, nn.Linear):\n","                module.weight.data.normal_(0, 0.01)\n","                module.bias.data.zero_()\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        # flatten\n","        x = x.view(x.size(0), -1)\n","        x = self.classifier(x)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9yqMCF7ft5is"},"outputs":[],"source":["class Block(nn.Module):\n","  def __init__(self,in_channels,out_channels,stride=1):\n","    super(Block,self).__init__()\n","    self.plain=nn.Sequential(\n","        nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU(),\n","        nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n","        nn.BatchNorm2d(out_channels)\n","    )\n","    #判斷strides是否等於1，輸出入channel是否相等，否就做downsample使用1x1convolution(stride=2=>3x3=>1x1)\n","    if stride!=1 or in_channels!=out_channels: \n","      self.shortcut=nn.Sequential(\n","          nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n","          nn.BatchNorm2d(out_channels)\n","      )\n","    self.short_cut=(stride!=1) or (in_channels!=out_channels)\n","  def forward(self,inputs):\n","    x=self.plain(inputs)\n","    if not self.short_cut:\n","      shortcut=inputs\n","    else:\n","      shortcut=self.shortcut(inputs)\n","    # print(x.shape)\n","    # print(shortcut.shape)\n","    return x+shortcut\n","\n","class ResNet(nn.Module):\n","  def __init__(self):\n","    super(ResNet, self).__init__()\n","    self.model=nn.Sequential(\n","        Block(3,64),\n","        Block(64,64),\n","        Block(64,256,2),\n","\n","        Block(256,128),\n","        Block(128,128),\n","        Block(128,512,2),\n","\n","        Block(512,256),\n","        Block(256,256),\n","        Block(256,1024,2),\n","\n","        Block(1024,512),\n","        Block(512,512),\n","        Block(512,2048,2),\n","\n","        nn.AdaptiveAvgPool2d((1,1)),\n","        nn.Flatten(),\n","        nn.Linear(2048,2048),\n","        nn.ReLU(),\n","        nn.Dropout(0.2),\n","        nn.Linear(2048,2048),\n","        nn.ReLU(),\n","        nn.Dropout(0.2),\n","        nn.Linear(2048, 2)\n","    )\n","  def forward(self,inputs):\n","    # x=self.block1(inputs)\n","    y=self.model(inputs)\n","    return y"]},{"cell_type":"markdown","metadata":{"id":"Zok09BP65uou"},"source":["#Train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kEbNduk_50Fr","outputId":"cd07a482-bddd-4deb-dfb5-5f2c7cbcf9f6","executionInfo":{"status":"ok","timestamp":1647788498587,"user_tz":-480,"elapsed":1398944,"user":{"displayName":"林楷軒","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02820282684866856866"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",")\n","Epoch: 1/20 --- < Starting Time : Sun Mar 20 14:38:20 2022 >\n","------------------------------------------------------------\n","Training loss: 1.0064\taccuracy: 0.5164\n","\n","Accuracy of   cnv :  53.3333 %\n","Accuracy of   pcv :  31.5068 %\n","\n","Accuracy on the ALL test images: 41.9929 %\n","Epoch: 2/20 --- < Starting Time : Sun Mar 20 14:39:31 2022 >\n","------------------------------------------------------------\n","Training loss: 0.7091\taccuracy: 0.4943\n","\n","Accuracy of   cnv : 100.0000 %\n","Accuracy of   pcv :   0.0000 %\n","\n","Accuracy on the ALL test images: 48.0427 %\n","Epoch: 3/20 --- < Starting Time : Sun Mar 20 14:40:40 2022 >\n","------------------------------------------------------------\n","Training loss: 0.6765\taccuracy: 0.5447\n","\n","Accuracy of   cnv :  48.8889 %\n","Accuracy of   pcv :  32.8767 %\n","\n","Accuracy on the ALL test images: 40.5694 %\n","Epoch: 4/20 --- < Starting Time : Sun Mar 20 14:41:50 2022 >\n","------------------------------------------------------------\n","Training loss: 0.6730\taccuracy: 0.5694\n","\n","Accuracy of   cnv :  35.5556 %\n","Accuracy of   pcv :  41.7808 %\n","\n","Accuracy on the ALL test images: 38.7900 %\n","Epoch: 5/20 --- < Starting Time : Sun Mar 20 14:42:59 2022 >\n","------------------------------------------------------------\n","Training loss: 0.6708\taccuracy: 0.5774\n","\n","Accuracy of   cnv :  67.4074 %\n","Accuracy of   pcv :  34.9315 %\n","\n","Accuracy on the ALL test images: 50.5338 %\n","Epoch: 6/20 --- < Starting Time : Sun Mar 20 14:44:09 2022 >\n","------------------------------------------------------------\n","Training loss: 0.6522\taccuracy: 0.6269\n","\n","Accuracy of   cnv :  22.2222 %\n","Accuracy of   pcv :  59.5890 %\n","\n","Accuracy on the ALL test images: 41.6370 %\n","Epoch: 7/20 --- < Starting Time : Sun Mar 20 14:45:18 2022 >\n","------------------------------------------------------------\n","Training loss: 0.6422\taccuracy: 0.6304\n","\n","Accuracy of   cnv :  34.0741 %\n","Accuracy of   pcv :  40.4110 %\n","\n","Accuracy on the ALL test images: 37.3665 %\n","Epoch: 8/20 --- < Starting Time : Sun Mar 20 14:46:28 2022 >\n","------------------------------------------------------------\n","Training loss: 0.6285\taccuracy: 0.6543\n","\n","Accuracy of   cnv :  29.6296 %\n","Accuracy of   pcv :  47.2603 %\n","\n","Accuracy on the ALL test images: 38.7900 %\n","Epoch: 9/20 --- < Starting Time : Sun Mar 20 14:47:38 2022 >\n","------------------------------------------------------------\n","Training loss: 0.6298\taccuracy: 0.6393\n","\n","Accuracy of   cnv :  25.1852 %\n","Accuracy of   pcv :  43.8356 %\n","\n","Accuracy on the ALL test images: 34.8754 %\n","Epoch: 10/20 --- < Starting Time : Sun Mar 20 14:48:49 2022 >\n","-------------------------------------------------------------\n","Training loss: 0.6180\taccuracy: 0.6649\n","\n","Accuracy of   cnv :  22.9630 %\n","Accuracy of   pcv :  45.2055 %\n","\n","Accuracy on the ALL test images: 34.5196 %\n","Epoch: 11/20 --- < Starting Time : Sun Mar 20 14:49:59 2022 >\n","-------------------------------------------------------------\n","Training loss: 0.6129\taccuracy: 0.6667\n","\n","Accuracy of   cnv :  26.6667 %\n","Accuracy of   pcv :  46.5753 %\n","\n","Accuracy on the ALL test images: 37.0107 %\n","Epoch: 12/20 --- < Starting Time : Sun Mar 20 14:51:10 2022 >\n","-------------------------------------------------------------\n","Training loss: 0.6003\taccuracy: 0.6702\n","\n","Accuracy of   cnv :  34.8148 %\n","Accuracy of   pcv :  37.6712 %\n","\n","Accuracy on the ALL test images: 36.2989 %\n","Epoch: 13/20 --- < Starting Time : Sun Mar 20 14:52:20 2022 >\n","-------------------------------------------------------------\n","Training loss: 0.6023\taccuracy: 0.6702\n","\n","Accuracy of   cnv :  18.5185 %\n","Accuracy of   pcv :  43.8356 %\n","\n","Accuracy on the ALL test images: 31.6726 %\n","Epoch: 14/20 --- < Starting Time : Sun Mar 20 14:53:30 2022 >\n","-------------------------------------------------------------\n","Training loss: 0.6056\taccuracy: 0.6702\n","\n","Accuracy of   cnv :  17.0370 %\n","Accuracy of   pcv :  42.4658 %\n","\n","Accuracy on the ALL test images: 30.2491 %\n","Epoch: 15/20 --- < Starting Time : Sun Mar 20 14:54:39 2022 >\n","-------------------------------------------------------------\n","Training loss: 0.5994\taccuracy: 0.6888\n","\n","Accuracy of   cnv :  25.9259 %\n","Accuracy of   pcv :  39.0411 %\n","\n","Accuracy on the ALL test images: 32.7402 %\n","Epoch: 16/20 --- < Starting Time : Sun Mar 20 14:55:49 2022 >\n","-------------------------------------------------------------\n","Training loss: 0.5996\taccuracy: 0.6808\n","\n","Accuracy of   cnv :  22.2222 %\n","Accuracy of   pcv :  41.7808 %\n","\n","Accuracy on the ALL test images: 32.3843 %\n","Epoch: 17/20 --- < Starting Time : Sun Mar 20 14:56:59 2022 >\n","-------------------------------------------------------------\n","Training loss: 0.6080\taccuracy: 0.6737\n","\n","Accuracy of   cnv :  26.6667 %\n","Accuracy of   pcv :  38.3562 %\n","\n","Accuracy on the ALL test images: 32.7402 %\n","Epoch: 18/20 --- < Starting Time : Sun Mar 20 14:58:08 2022 >\n","-------------------------------------------------------------\n","Training loss: 0.5917\taccuracy: 0.6729\n","\n","Accuracy of   cnv :  21.4815 %\n","Accuracy of   pcv :  41.0959 %\n","\n","Accuracy on the ALL test images: 31.6726 %\n","Epoch: 19/20 --- < Starting Time : Sun Mar 20 14:59:18 2022 >\n","-------------------------------------------------------------\n","Training loss: 0.6015\taccuracy: 0.6808\n","\n","Accuracy of   cnv :  27.4074 %\n","Accuracy of   pcv :  39.0411 %\n","\n","Accuracy on the ALL test images: 33.4520 %\n","Epoch: 20/20 --- < Starting Time : Sun Mar 20 15:00:27 2022 >\n","-------------------------------------------------------------\n","Training loss: 0.5984\taccuracy: 0.6764\n","\n","Accuracy of   cnv :  23.7037 %\n","Accuracy of   pcv :  39.7260 %\n","\n","Accuracy on the ALL test images: 32.0285 %\n","Best model name : /content/drive/My Drive/colab_network/medical_image/M-model-0.69-best_train_acc.pth\n"]}],"source":["import torch\n","import torch.nn as nn\n","# from Model_VGG16 import VGG16\n","# from dataset import IMAGE_Dataset\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","from pathlib import Path\n","import copy\n","import time\n","import os\n","import torchvision.models as models\n","##REPRODUCIBILITY\n","torch.manual_seed(0)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","#args = parse_args()\n","#CUDA_DEVICES = args.cuda_devices\n","#DATASET_ROOT = args.path\n","CUDA_DEVICES = 0\n","DATASET_ROOT = '/content/drive/My Drive/colab_network/medical image/train/'\n","DATASET_valROOT = '/content/drive/My Drive/colab_network/medical image/val/'\n","PATH_TO_WEIGHTS = '/content/model-0.80-best_train_acc.pth' # Your model name\n","\n","# Initial learning rate\n","init_lr = 0.01\n","\n","# Save model every 5 epochs\n","checkpoint_interval = 5\n","if not os.path.isdir('/content/drive/My Drive/colab_network/medical_image/Checkpoint/'):\n","    os.mkdir('/content/drive/My Drive/colab_network/medical_image/Checkpoint/')\n","\n","\n","# Setting learning rate operation\n","def adjust_lr(optimizer, epoch):\n","    \n","    # 1/10 learning rate every 5 epochs\n","    lr = init_lr * (0.1 ** (epoch // 5))\n","    \n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","\n","def train():\n","    data_transform = transforms.Compose([\n","        transforms.Resize((224,224)),\n","        # transforms.RandomCrop(224, pad_if_needed=True),\n","        # transforms.RandomRotation(2.8),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","        ])\n","    #print(DATASET_ROOT)\n","    train_set = IMAGE_Dataset(Path(DATASET_ROOT), data_transform)\n","    \n","    # If out of memory , adjusting the batch size smaller\n","    data_loader = DataLoader(dataset=train_set, batch_size=16, shuffle=True, num_workers=0)#16改128\n","\n","    val_set = IMAGE_Dataset(Path(DATASET_valROOT), data_transform)\n","    val_data_loader = DataLoader(dataset=val_set, batch_size=16, shuffle=True, num_workers=0)\n","    classes = [_dir.name for _dir in Path(DATASET_valROOT).glob('*')]\n","    classes.sort()\n","    classes.sort(key = len)\n","    #print(train_set.num_classes)\n","    # model = VGG16(num_classes=train_set.num_classes)\n","    # model = ResNet()\n","    #model=models.shufflenet_v2_x1_0(pretrained=True)\n","    num_classes = 2\n","    \n","    model = models.resnet50(pretrained=True)\n","\n","    num_features = model.fc.out_features\n","    model.fc = nn.Linear(2048,2)\n","    #model.add_module(\"add_dropout\",nn.Dropout())\n","    #model.add_module(\"add_fc\",nn.Linear(num_features, num_classes))\n","    #model = models.vgg19(pretrained=True)\n","    #model.classifier[6] = nn.Linear(in_features=4096, out_features=2, bias=True)\n","    model = model.cuda(CUDA_DEVICES)\n","    \n","    #para_optim = []\n","    #for i, single_layer in  enumerate(model.modules()):\n","    #    print(i, single_layer)\n","    #if i > 50:      # 前面37层冻结\n","    #  for param in single_layer.parameters():\n","    #         para_optim.append(param)\n","    #  else:           # 后面7层不冻结正常更新\n","    #     for param in single_layer.parameters():\n","    #         param.requires_grad = False\n","    #print(f'para_optim len = {len(para_optim)}')\n","    print(model)\n","    model.train()\n","\n","    best_model_params = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","    \n","    # Training epochs\n","    num_epochs = 20 #20改3\n","    criterion = nn.CrossEntropyLoss()\n","    \n","    # Optimizer setting\n","    #optimizer = torch.optim.SGD(params=model.parameters(), lr=init_lr, momentum=0.9)\n","    #optimizer = torch.optim.RMSprop(params=model.parameters(), lr=init_lr, alpha=0.9)\n","    optimizer = torch.optim.Adam(params=model.parameters(), lr=init_lr)\n","    # Log \n","    with open('TrainingAccuracy.txt','w') as fAcc:\n","        print('Accuracy\\n', file = fAcc)\n","    with open('TrainingLoss.txt','w') as fLoss:\n","        print('Loss\\n', file = fLoss)\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        localtime = time.asctime( time.localtime(time.time()) )\n","        print('Epoch: {}/{} --- < Starting Time : {} >'.format(epoch + 1,num_epochs,localtime))\n","        print('-' * len('Epoch: {}/{} --- < Starting Time : {} >'.format(epoch + 1,num_epochs,localtime)))\n","\n","        training_loss = 0.0\n","        training_corrects = 0\n","        adjust_lr(optimizer, epoch)\n","\n","        for i, (inputs, labels) in enumerate(data_loader):\n","            inputs = Variable(inputs.cuda(CUDA_DEVICES))\n","            labels = Variable(labels.cuda(CUDA_DEVICES))\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs.data, 1)\n","            loss = criterion(outputs, labels)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            training_loss += float(loss.item() * inputs.size(0))\n","            training_corrects += torch.sum(preds == labels.data)\n","        training_loss = training_loss / len(train_set)\n","        training_acc = training_corrects.double() /len(train_set)\n","        print('Training loss: {:.4f}\\taccuracy: {:.4f}\\n'.format(training_loss,training_acc))\n","        \n","\n","        # Check best accuracy model ( but not the best on test )\n","        if training_acc > best_acc:\n","            best_acc = training_acc\n","            best_model_params = copy.deepcopy(model.state_dict())\n","\n","\n","        with open('TrainingAccuracy.txt','a') as fAcc:\n","            print('{:.4f} '.format(training_acc), file = fAcc)\n","        with open('TrainingLoss.txt','a') as fLoss:\n","            print('{:.4f} '.format(training_loss), file = fLoss)\n","\n","        # Checkpoint\n","        if (epoch + 1) % checkpoint_interval == 0:\n","            torch.save(model, '/content/drive/My Drive/colab_network/medical_image/M-model-epoch-{:d}-train.pth'.format(epoch + 1))\n","        # DATASET_valROOT = '/content/drive/My Drive/Colab Notebooks/medical image/test/'\n","    # PATH_TO_WEIGHTS = '/content/model-0.54-best_train_acc.pth' # Your model name\n","\n","    \n","\n","    # Load model\n","    # model = torch.load(PATH_TO_WEIGHTS)\n","    # model = model.cuda(CUDA_DEVICES)\n","        model.eval()\n","        total_correct = 0\n","        total = 0\n","        class_correct = list(0. for i in enumerate(classes))\n","        class_total = list(0. for i in enumerate(classes))\n","\n","        with torch.no_grad():\n","            for inputs, labels in val_data_loader:\n","                inputs = Variable(inputs.cuda(CUDA_DEVICES))\n","                labels = Variable(labels.cuda(CUDA_DEVICES))\n","                outputs = model(inputs)\n","                _, predicted = torch.max(outputs.data, 1)\n","                \n","                # totoal\n","                total += labels.size(0)\n","                total_correct += (predicted == labels).sum().item()\n","                c = (predicted == labels).squeeze()\n","                \n","                # batch size\n","                for i in range(labels.size(0)):\n","                    label = labels[i]\n","                    class_correct[label] += c[i].item()\n","                    class_total[label] += 1\n","\n","            for i, c in enumerate(classes):\n","                print('Accuracy of %5s : %8.4f %%' % (\n","                c, 100 * class_correct[i] / class_total[i]))\n","\n","            # Accuracy\n","            print('\\nAccuracy on the ALL test images: %.4f %%'\n","              % (100 * total_correct / total))\n","    # Save best training/valid accuracy model ( not the best on test )\n","    model.load_state_dict(best_model_params)\n","    best_model_name = '/content/drive/My Drive/colab_network/medical_image/M-model-{:.2f}-best_train_acc.pth'.format(best_acc)\n","    torch.save(model, best_model_name)\n","    print(\"Best model name : \" + best_model_name)\n","    total = sum([param.nelement() for param in model.parameters()])\n","    print(\"Number of parameter: %.2fM\" % (total/1e6))\n","\n","\n","if __name__ == '__main__':\n","    train()\n","    \n"]},{"cell_type":"markdown","metadata":{"id":"-qlrbY_tGFIh"},"source":["#val"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zzKJGmVuGCjn"},"outputs":[],"source":["import torch\n","# from utils import parse_args\n","from torch.autograd import Variable\n","from torchvision import transforms\n","from pathlib import Path\n","from PIL import Image\n","from torch.utils.data import DataLoader\n","# from dataset import IMAGE_Dataset\n","import numpy as np\n","\n","CUDA_DEVICES = 0\n","DATASET_valROOT = '/content/drive/My Drive/colab_network/medical image/val/'\n","PATH_TO_WEIGHTS = '/content/model-0.54-best_train_acc.pth' # Your model name\n","\n","\n","def val():\n","    CUDA_DEVICES = 0\n","    #DATASET_valROOT = '/content/drive/My Drive/colab_network/medical image/test/'\n","    # PATH_TO_WEIGHTS = '/content/model-0.54-best_train_acc.pth' # Your model name\n","\n","    data_transform = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[\n","                             0.229, 0.224, 0.225])\n","    ])\n","    val_set = IMAGE_Dataset(Path(DATASET_valROOT), data_transform)\n","    val_data_loader = DataLoader(\n","        dataset=val_set, batch_size=32, shuffle=True, num_workers=0)\n","    classes = [_dir.name for _dir in Path(DATASET_valROOT).glob('*')]\n","    classes.sort()\n","    classes.sort(key = len)\n","\n","    # Load model\n","    model = torch.load(PATH_TO_WEIGHTS)\n","    model = model.cuda(CUDA_DEVICES)\n","    model.eval()\n","    total_correct = 0\n","    total = 0\n","    class_correct = list(0. for i in enumerate(classes))\n","    class_total = list(0. for i in enumerate(classes))\n","\n","    with torch.no_grad():\n","        for inputs, labels in val_data_loader:\n","            inputs = Variable(inputs.cuda(CUDA_DEVICES))\n","            labels = Variable(labels.cuda(CUDA_DEVICES))\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            \n","            # totoal\n","            total += labels.size(0)\n","            total_correct += (predicted == labels).sum().item()\n","            c = (predicted == labels).squeeze()\n","            \n","            # batch size\n","            for i in range(labels.size(0)):\n","                label = labels[i]\n","                class_correct[label] += c[i].item()\n","                class_total[label] += 1\n","\n","    for i, c in enumerate(classes):\n","        print('Accuracy of %5s : %8.4f %%' % (\n","        c, 100 * class_correct[i] / class_total[i]))\n","\n","    # Accuracy\n","    print('\\nAccuracy on the ALL test images: %.4f %%'\n","      % (100 * total_correct / total))\n","\n","\n","\n","if __name__ == '__main__':\n","    val()"]},{"cell_type":"markdown","metadata":{"id":"u8VWhXTn50sm"},"source":["#test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11008,"status":"ok","timestamp":1647788527055,"user":{"displayName":"林楷軒","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02820282684866856866"},"user_tz":-480},"id":"KhG0T3vu513D","outputId":"dca1208a-d5da-4507-8090-9a2080fcccc4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of   cnv :  54.6012 %\n","Accuracy of   pcv :  74.5098 %\n","\n","Accuracy on the ALL test images: 64.2405 %\n"]}],"source":["import torch\n","# from utils import parse_args\n","from torch.autograd import Variable\n","from torchvision import transforms\n","from pathlib import Path\n","from PIL import Image\n","from torch.utils.data import DataLoader\n","# from dataset import IMAGE_Dataset\n","import numpy as np\n","\n","CUDA_DEVICES = 0\n","DATASET_ROOT = '/content/drive/My Drive/colab_network/medical image/test/'\n","PATH_TO_WEIGHTS = '/content/drive/My Drive/colab_network/medical_image/M-model-0.69-best_train_acc.pth' # Your model name\n","\n","\n","def test():\n","    data_transform = transforms.Compose([\n","        transforms.Resize((224, 224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[\n","                             0.229, 0.224, 0.225])\n","    ])\n","    test_set = IMAGE_Dataset(Path(DATASET_ROOT), data_transform)\n","    data_loader = DataLoader(\n","        dataset=test_set, batch_size=32, shuffle=True, num_workers=0)\n","    classes = [_dir.name for _dir in Path(DATASET_ROOT).glob('*')]\n","    classes.sort()\n","    classes.sort(key = len)\n","\n","    # Load model\n","    model = torch.load(PATH_TO_WEIGHTS)\n","    model = model.cuda(CUDA_DEVICES)\n","    model.eval()\n","    \n","\n","    total_correct = 0\n","    total = 0\n","    class_correct = list(0. for i in enumerate(classes))\n","    class_total = list(0. for i in enumerate(classes))\n","\n","    with torch.no_grad():\n","        for inputs, labels in data_loader:\n","            inputs = Variable(inputs.cuda(CUDA_DEVICES))\n","            labels = Variable(labels.cuda(CUDA_DEVICES))\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs.data, 1)\n","            \n","            # totoal\n","            total += labels.size(0)\n","            total_correct += (predicted == labels).sum().item()\n","            c = (predicted == labels).squeeze()\n","            \n","            # batch size\n","            for i in range(labels.size(0)):\n","                label = labels[i]\n","                class_correct[label] += c[i].item()\n","                class_total[label] += 1\n","\n","    for i, c in enumerate(classes):\n","        print('Accuracy of %5s : %8.4f %%' % (\n","        c, 100 * class_correct[i] / class_total[i]))\n","\n","    # Accuracy\n","    print('\\nAccuracy on the ALL test images: %.4f %%'\n","      % (100 * total_correct / total))\n","\n","\n","\n","if __name__ == '__main__':\n","    test()"]},{"cell_type":"markdown","metadata":{"id":"AVmbwbu-54oP"},"source":["#util(不用跑~)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ri6aqdqB56Yl"},"outputs":[],"source":["import argparse\n","\n","def parse_args():\n","    desc = 'PyTorch example code for Kaggle competition -- Plant Seedlings Classification.\\n' \\\n","           'See https://www.kaggle.com/c/plant-seedlings-classification'\n","    parser = argparse.ArgumentParser(description=desc)\n","    parser.add_argument('-p', '--path', help='path to dataset')\n","    parser.add_argument('-w', '--weight', help='path to model weights')\n","    parser.add_argument('-c', '--cuda_devices', type=int, help='path to model weights')\n","    return parser.parse_args()"]}],"metadata":{"colab":{"name":"醫學影像專題p1 (1).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}